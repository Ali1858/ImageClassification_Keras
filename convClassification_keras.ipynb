{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disclaimer ----------------------------------------------------------\n",
    "#---------------------------------------------------------------------\n",
    "#This code for learning purpose only \n",
    "#it may or may not give you high accuracy required for competition .\n",
    "#since i dont have GPU to train u used my laptop \n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense,Lambda,Flatten,Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "FILES_PATH = 'http://files.fast.ai/models/' #path for vgg network weight . you can download from official website also \n",
    "path = \"Data/DogVsCat/\"\n",
    "#path = \"Data/DogVsCat/sample/\"\n",
    "\n",
    "model_path = path + 'models/' #to save weight for our final model\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution2d(layer,model,filter):\n",
    "    for i in range(layer):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filter,3,3,activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FullyConnected(model):\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean \n",
    "    # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG16():\n",
    "    model = Sequential()\n",
    "    #First Layer \n",
    "    model.add(Lambda(vgg_preprocess,input_shape=(3,224,224)))\n",
    "    #Block 1 with 2 layer\n",
    "    convolution2d(2,model,64)\n",
    "    #Block 2 with 2 layer\n",
    "    convolution2d(2,model,128)\n",
    "    #Block 3 with 3 layer \n",
    "    convolution2d(3,model,256)\n",
    "    #Block 4 with 3 layer\n",
    "    convolution2d(3,model,512)\n",
    "    #Block 5 with 3 layer\n",
    "    convolution2d(3,model,512)\n",
    "    #Flatten Layer\n",
    "    model.add(Flatten())\n",
    "    #Fully Connected Layer\n",
    "    FullyConnected(model)\n",
    "    FullyConnected(model)\n",
    "    #output layer with softmax\n",
    "    model.add(Dense(1000,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 224, 224)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = VGG16() # create our own VGG16 network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = get_file('vgg16.h5', FILES_PATH+'vgg16.h5', cache_subdir='models')#download weight for  model \n",
    "model.load_weights(fpath)#load weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop() #pop the last layer and add our own layer , since this classifier doesnt have 1000 classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable=False #do not train first 15 layer \n",
    "\n",
    "model.add(Dense(2,activation='softmax')) # add one Fully connected layer  with 2 output because we have \n",
    "                                        #classes and train only this layer  \n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])#set optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = get_batches('train',batch_size=batch_size)\n",
    "val_images = get_batches('val',batch_size=batch_size)\n",
    "img,label = next(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 15473s - loss: 0.1057 - acc: 0.9629 - val_loss: 0.0950 - val_acc: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a02fea278>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_images, samples_per_epoch=train_images.n, nb_epoch=1, validation_data=val_images, nb_val_samples=val_images.n)\n",
    "\n",
    "#you can set your own epoch size . \n",
    "#i only train it for one epoch because of resource limitation (only one epoch took me  5 hours to train)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(model_path+'finetune1.h5')\n",
    "model.load_weights(model_path+'finetune1.h5')\n",
    "# save all trained weight , so you can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image = get_batches('test',batch_size=batch_size) # load test image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "results = model.predict_generator(test_image,test_image.nb_sample)\n",
    "# predict for all test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bcolz you to save array in your directory \n",
    "import bcolz\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving predicted result in local directory\n",
    "save_array(path + 'test_preds.dat', result)\n",
    "save_array(path + 'filenames.dat', test_image.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = load_array(path+'test_preds.dat')\n",
    "filename = load_array(path+'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.34522736e-03,   9.98654783e-01],\n",
       "       [  3.51411253e-01,   6.48588777e-01],\n",
       "       [  4.68529016e-03,   9.95314717e-01],\n",
       "       [  1.00000000e+00,   2.16642958e-12],\n",
       "       [  1.47995213e-02,   9.85200465e-01],\n",
       "       [  9.99998391e-01,   1.57970237e-06],\n",
       "       [  9.25120115e-02,   9.07487988e-01],\n",
       "       [  1.00000000e+00,   2.34677746e-14],\n",
       "       [  1.00000000e+00,   1.53770524e-13],\n",
       "       [  1.71022187e-03,   9.98289764e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ids for your prediction . for submitting in to competition\n",
    "ids = np.array([int(f[5:f.find('.')]) for f in filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['test\\\\1.jpg', 'test\\\\10.jpg', 'test\\\\100.jpg', 'test\\\\1000.jpg',\n",
       "       'test\\\\10000.jpg'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,    10,   100,  1000, 10000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_dog = mresult[:,1]\n",
    "is_dog = is_dog.clip(0.05,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concat two array \n",
    "final_result = np.stack([ids,is_dog],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.00000007e-02],\n",
       "       [  1.00000000e+01,   3.51411253e-01],\n",
       "       [  1.00000000e+02,   5.00000007e-02],\n",
       "       [  1.00000000e+03,   9.49999988e-01],\n",
       "       [  1.00000000e+04,   5.00000007e-02]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file as csv for submission\n",
    "submission_file_name = 'submission.csv'\n",
    "np.savetxt(submission_file_name, final_result, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
